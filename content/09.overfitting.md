## Tip 7: Address deep neural networks' increased tendency to overfit the dataset {#overfitting}

Overfitting is one of the most pernicious dangers faced by a deep learning practitioner.
Put simply, overfitting is when a model–deep or otherwise–memorizes the mapping from inputs to outputs rather than truly learning.
This subtle distinction is made clearer by seeing what happens when a model is tested on data to which it was not exposed during training: just as a student who memorizes exam materials struggles to correctly answer questions for which they have not studied, a machine learning model that has overfit to its training data will perform poorly on unseen test data.
Deep learning models are particularly susceptible to overfitting due to their greater representational capacity.
To continue the student analogy, a smarter student has greater potential for memorization than average one and thus may be more inclined to memorize.

The simplest way to combat overfitting is to detect it.
This can be done by splitting the dataset into three parts: a training set, a tuning set (also commonly called a validation set), and a testing set.
By exposing the model solely to the training data during fitting, a researcher can use the model's performance on the unseen test data to measure the amount of overfitting.
While a slight drop in performance from the training set to the test set is normal, a significant drop is a clear sign of overfitting.
Additionally, there are a variety of techniques to reduce overfitting during training including data augmentation, regularization, dropout [@url:http://dl.acm.org/citation.cfm?id=2627435.2670313] and weight decay [@url:http://dl.acm.org/citation.cfm?id=2986916.2987033].

Additionally, one must be sure that their data are not skewed or biased, such as by having confounding variables that the model can pick up on [@arxiv:1[807.00431](https://arxiv.org/abs/1807.00431)].
In this case, simply holding out test data is insufficient.
The best remedy for confounding variables is to [know your data][#know-your-problem] and to test your model on truly independent data.
