## Tip 5: Choose an appropriate data representation and neural network architecture {#architecture}
Unfortunately, choosing how to represent your data and design your architecture is closer to an art than a science.
While certain best practices have been established by the research community [doi:10.1007/978-3-642-35289-8], architecture design choices remain largely problem-specific and vastly empirical efforts requiring extensive experimentation.
Furthermore, as deep learning is a quickly evolving field, many recommendations are often short-lived and frequently replaced by newer insights supported by recent empirical results.
This is further complicated by the fact that many recommendations are very problem- and dataset-specific and do not generalize well across different tasks.
With that being said, there are some general principles that are useful to follow when experimenting.

First and foremost, use your knowledge of the available data and your question (see [Tip 4](#know-your-problem)) to inform your data representation and architectural design choices.
For example, if your data is an array of measurements with no natural ordering of inputs (such as gene expression data), multilayer perceptrons (MLPs), which are the most basic type of neural network, may be effective.
Similarly, if your data is comprised of images, convolutional neural networks (CNNs) are a good choice because they emphasize local structures and adjacency within the data.

In the event that there is not enough data available to train your model, consider using transfer learning.
In transfer learning, a model whose weights were generated by training on another dataset is used as the starting point for training [@tag:Yosinski2014].
