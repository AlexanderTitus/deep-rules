## Tip 2: Use traditional methods to establish performance baselines {#baselines}

Before diving into a fancy thousand-layer neural network, always implement at least a simple model to establish an adequate performance baseline.
For example, researchers can build multinomial logistic regression or random forest models using the same software framework that is being used for DL and evaluate its classification performance.
This approach will help researchers with assessing the complexity of the task at hand and debugging more complex DL architectures.
The utility of these methods is evidenced by the recent development of hybrid models which combine DL and simpler models to improve robustness, interpretability, and confidence estimation [@arxiv:1803.04765; @arxiv:1805.11783].
Depending on the amount of available data and the type of tasks, DL models may not necessarily be the best performing one.
As an illustration, the simple baseline models by Rajkomar et al. [@doi:10.1038/s41746-018-0029-1] achieved performance comparable with that of DL in a number of clinical prediction tasks using electronic health records, which may be a surprise to many.

It is worth noting that conventional machine learning methods (e.g., support vector machines, random forests) are also likely to benefit from parameter tuning.
It can be tempting to train baseline models with these conventional methods using default parameters, which may provide acceptable but not stellar performance, but then tune the parameters for DL models to optimize performance.
Hu and Greene [@doi:10.1101/385534] discuss a Continental Breakfast Included effect by which unequal hyperparameter tuning skews the evaluation of methods, especially those with performance that varies substantially with modest changes to hyperparameters.
Those wishing to compare methods should tune the parameters of traditional and DL to optimize performance before making claims about relative performance differences.
The performance comparison among DL models and many other ML approaches is informative only when the models are similarly tuned.
