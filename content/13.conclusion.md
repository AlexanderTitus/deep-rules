## Concluding remarks and ethics-related considerations {#conclusion}
While DL continues to be a powerful, transformative tool within life sciences research—spanning basic biology and pre-clinical science to varied translational approaches and clinical studies—it is important to comment on some ethics-related considerations. 
For instance, despite that DL methods are helping to increase medical efficiency through improved diagnostic capability and risk assessment, certain biases may be inadvertently introduced into models related to patient age, race, and gender [@doi:10.1002/hast.977]; as previously mentioned, DL practitioners may make use of datasets lacking diverse populations and patient characteristics [@doi:10.1377/hlthaff.2014.0048], thereby contributing to these problems (please refer to Tip 4).
Beyond healthcare, DL can also reinforce societal prejudices of race [@https://www.theatlantic.com/business/archive/2015/09/discrimination-algorithms-disparate-impact/403969/; @https://www.nytimes.com/2016/06/26/opinion/sunday/artificial-intelligences-white-guy-problem.html]. 

Therefore, it is important to think thoroughly and cautiously about DL applications and its potential impact to persons and society—mindful of possible harms, injuries, injustices, and other types of wrongdoings. 
At a minimum, colleagues must ensure that, wherever relevant, their life sciences projects are fully compliant with local research governance/approval policies, legal requirements, Institutional Review Board (IRB) policies, and any other relevant bodies and their standards. 
Moreover, we offer below three tangible, action-oriented recommendations to further empower and enrichen DL researchers. 

First, similarly to how certain teams keep a project-specific or coding-related register—that is, detailing more about known bugs and other technical risks and issues—colleagues should get into the habit of keeping an active *ethics register*. 
Teams can institute what Rachel Thomas of the Center for Applied Data Ethics at the University of San Francisco terms “ethical risk sweeps.” Teams focus on “periodically scheduling times to really go through what could go wrong and what are the ethical risks.” 
After all, “ethics is thinking through what can go wrong before it does and having processes in place around what happens when there are mistakes or errors” [@https://venturebeat.com/2019/10/07/how-to-operationalize-ai-ethics/]. 
Second, to help foster a conscious ethics-oriented mindset, researchers should consider expanding journal clubs to include scholarly and popular articles detailing real-world ethics issues relevant to in their scientific fields. 
This will help researchers to think more holistically and judiciously (that is, with good judgment and sense) about their work and its implications. 
Third, we encourage individual- and team-level participation in professional societies and other types of organizations and initiatives related to AI/DL and data ethics [@https://ocean.sagepub.com/blog/10-organizations-leading-the-way-in-ethical-ai; @https://www.aies-conference.com/2021/; @http://ethics-artificial-intelligence-conference.mozello.com]. 
This will encourage a sense of community and intellectual engagement, keeping colleagues abreast of cutting-edge insights and emerging professional standards.

To this end, our manuscript is focused on the promotion of practical tips distilled from cutting-edge insights and evolving professional standards to advance the efficient and optimal application of DL within research.
It is evident that some of our points (see Tips 7, 8, 9, and 10) are intimately linked to safeguarding against key risks: for example, introduction/perpetuation of bias, overinterpretation/misinterpretation of models, poor generalizability, and potential for harm unto others—which can have a mix of ethical, legal, and social implications. 
If leveraged in ethical and responsible ways, DL techniques have the potential to add value within a diverse array of research and healthcare contexts, as these techniques have already shown remarkable capacity to meet or exceed the performance of human effort and/or older algorithms across fields and subdisciplines. 
Beyond merely achieving good predictive performance in certain tasks, DL has the potential to uncover high-impact biological and clinical insights, fundamentally driving research discoveries and delivery of new products to market. 
Yet, to realize its full potential, DL must be approached by all with genuine thoughtfulness, caution, and responsibility.

Through the tips and recommendations provided within this manuscript, we hope to encourage a prudent, vigilant community of computational practitioners, experimental biologists, and clinical scientists: colleagues who, before excitedly stitching together lines of code and datasets, first pause to think, dialogue, plan, and discern how their work might have far-reaching consequences with ethical dimensions. 
This holistic approach will help us to advance accountability, beneficence, and quality in science.

Thus, we aim not only to increase the accessibility of DL techniques within the life sciences, but also to improve upon the reproducibility and interpretability of high-quality DL research in the literature and scientific community—especially given that published findings, models, and datasets will be leveraged to yield innovative tools, services, and products in the marketplace. 
Indeed, we hope that these tips will serve as a powerful engine for promoting meaningful discussions, reflections, team learnings, and best practices to drive collaboration that fosters cutting-edge DL innovation, sensibly and responsibly.
