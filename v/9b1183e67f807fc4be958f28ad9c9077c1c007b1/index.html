<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Benjamin D. Lee" />
  <meta name="author" content="Alexander J. Titus" />
  <meta name="author" content="Kun-Hsing Yu" />
  <meta name="author" content="Marc G. Chevrette" />
  <meta name="author" content="Paul Allen Stewart" />
  <meta name="dcterms.date" content="2019-02-11" />
  <meta name="keywords" content="quick tips, machine learning, deep learning, artificial intelligence" />
  <title>Ten Quick Tips for Deep Learning in Biology</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="github-pandoc.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <!-- Insert Analytics Script Below -->
  <script>
  </script>
  <!-- End Analytics Script -->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Ten Quick Tips for Deep Learning in Biology</h1>
</header>
<p><small><em> This manuscript (<a href="https://Benjamin-Lee.github.io/deep-rules/v/9b1183e67f807fc4be958f28ad9c9077c1c007b1/">permalink</a>) was automatically generated from <a href="https://github.com/Benjamin-Lee/deep-rules/tree/9b1183e67f807fc4be958f28ad9c9077c1c007b1">Benjamin-Lee/deep-rules@9b1183e</a> on February 11, 2019. </em></small></p>
<h2 id="authors">Authors</h2>
<p>Please note the current author order is chronological and does not reflect the final order.</p>
<ul>
<li><p><strong>Benjamin D. Lee</strong><br> <img src="images/orcid.svg" alt="ORCID icon" width="13" height="13" /> <a href="https://orcid.org/0000-0002-7133-8397">0000-0002-7133-8397</a> · <img src="images/github.svg" alt="GitHub icon" width="13" height="13" /> <a href="https://github.com/Benjamin-Lee">Benjamin-Lee</a><br> <small> Lab41, In-Q-Tel; School of Engineering and Applied Sciences, Harvard University; Department of Genetics, Harvard Medical School </small></p></li>
<li><p><strong>Alexander J. Titus</strong><br> <img src="images/orcid.svg" alt="ORCID icon" width="13" height="13" /> <a href="https://orcid.org/0000-0002-0145-9564">0000-0002-0145-9564</a> · <img src="images/github.svg" alt="GitHub icon" width="13" height="13" /> <a href="https://github.com/AlexanderTitus">AlexanderTitus</a><br> <small> Titus Analytics </small></p></li>
<li><p><strong>Kun-Hsing Yu</strong><br> <img src="images/orcid.svg" alt="ORCID icon" width="13" height="13" /> <a href="https://orcid.org/0000-0001-9892-8218">0000-0001-9892-8218</a> · <img src="images/github.svg" alt="GitHub icon" width="13" height="13" /> <a href="https://github.com/khyu">khyu</a><br> <small> Department of Biomedical Informatics, Harvard Medical School </small></p></li>
<li><p><strong>Marc G. Chevrette</strong><br> <img src="images/orcid.svg" alt="ORCID icon" width="13" height="13" /> <a href="https://orcid.org/0000-0002-7209-0717">0000-0002-7209-0717</a> · <img src="images/github.svg" alt="GitHub icon" width="13" height="13" /> <a href="https://github.com/chevrm">chevrm</a><br> <small> Department of Genetics, University of Wisconsin-Madison; Department of Bacteriology, University of Wisconsin-Madison </small></p></li>
<li><p><strong>Paul Allen Stewart</strong><br> <img src="images/orcid.svg" alt="ORCID icon" width="13" height="13" /> <a href="https://orcid.org/0000-0003-0882-308X">0000-0003-0882-308X</a> · <img src="images/github.svg" alt="GitHub icon" width="13" height="13" /> <a href="https://github.com/pstew">pstew</a><br> <small> Biostatistics and Bioinformatics Shared Resource, Moffitt Cancer Center </small></p></li>
</ul>
<h2 id="intro">Introduction</h2>
<p>Deep learning (DL), a subfield of machine learning (ML) implementing artificial neural networks with many layers, is increasingly used for the analysis of biological data <span class="citation" data-cites="PZMP42Ak">[<a href="#ref-PZMP42Ak">1</a>]</span>. Despite its growing popularity, DL itself remains an active area of research. Its everchanging complexity and lack of current beginner resources focused on biological applications pose large barriers of entry to newcomers who wish to utilize state-of-the-art DL in their research. Biological insight garnered from DL has been well-documented in the scientific literature, with applications ranging from predicting protein-drug binding kinetics <span class="citation" data-cites="lwg6sPLT">[<a href="#ref-lwg6sPLT">2</a>]</span> to identifying the lab-of-origin of synthetic DNA <span class="citation" data-cites="WGfstNkj">[<a href="#ref-WGfstNkj">3</a>]</span>. However, few resources articulate DL best practices to the scientific community. Most instructional literature focuses on ML broadly, rather than DL specifically, further limiting accessibility and reproducibility <span class="citation" data-cites="p4Nl5If0">[<a href="#ref-p4Nl5If0">4</a>]</span>. To address this issue, we solicited input from a diverse community of researchers, who wrote this manuscript collaboratively using the GitHub version control platform <span class="citation" data-cites="ysdRl4lj">[<a href="#ref-ysdRl4lj">5</a>]</span> and Manubot <span class="citation" data-cites="1GGGHdsew">[<a href="#ref-1GGGHdsew">6</a>]</span>.</p>
<p>In the course of our discussions, several themes became clear: the importance of understanding and applying ML fundamentals as a baseline for utilizing DL, the necessity for extensive model comparisons and careful evaluation, and the need for critical thought in interpreting results generated by means of DL, among others. Ultmately, the tips we established range from high-level guidance to the implementation of best practices, and it is our hope that they will provide actionable, DL-specific advice for both new and experienced DL practitioners alike who would like to employ DL in biological research. By increasing the accessibility of DL techniques to biology, we aim to improve the overall quality and reproducibility of DL in the literature, enabling these powerful methods to be properly utilized to generate new scientific insights.</p>
<h2 id="concepts">Tip 1: Concepts that apply to machine learning also apply to deep learning</h2>
<p>Deep learning is a distinct subfield of machine learning, but it is still a subfield. DL has proven to be an extremely powerful paradigm capable of outperforming “traditional” machine learning approaches in certain contexts, but it is not immune to the many limitations inherent to machine learning. Many best practices for machine learning also apply to deep learning. For instance, deep supervised learning models should be trained, tuned, and tested on non-overlapping datasets. Those developing deep learning models should select data that are relevant to the problem at hand; non-salient data can hamper performance or lead to spurious conclusions. Furthermore, investigators should begin by thoroughly inspecting their data. When coupled with imprudence, data that is biased, skewed, or of low quality will produce models of dubious performance and limited generalizability. Biases in testing data can also unduly influence measures of model performance. For example, many conventional metrics for classification (e.g. area under the receiver operating characteristic curve or AUROC) have limited utility in cases of extreme class imbalance <span class="citation" data-cites="u86hHJ9b">[<a href="#ref-u86hHJ9b">7</a>]</span>. As such, model performance should be evaluated with a carefully-picked panel of relevant metrics that make minimal assumptions about the composition of the testing data <span class="citation" data-cites="rKXyJKNt">[<a href="#ref-rKXyJKNt">8</a>]</span>. Extreme cases warrant testing the robustness of the model and metrics on simulated data for which the ground truth is known. Said simulations can be used to verify the correctness of the model’s implementation as well. Like all computational methods, deep learning should be leveraged in a systematic manner that is reproducible and rigorously tested.</p>
<h2 id="baselines">Tip 2: Use traditional methods to establish performance baselines</h2>
<p>Before diving into a fancy thousand-layer neural network, always implement at least a simple model to establish an adequate performance baseline. For example, researchers can build multinomial logistic regression or random forest models using the same software framework that is being used for DL and evaluate its classification performance. This approach will help researchers with assessing the complexity of the task at hand and debugging more complex DL architectures. The utility of these methods is evidenced by the recent development of hybrid models which combine DL and simpler models to improve robustness, interpretability, and confidence estimation <span class="citation" data-cites="uBcf6TJ2 2bsGpiQt">[<a href="#ref-2bsGpiQt">10</a>,<a href="#ref-uBcf6TJ2">9</a>]</span>. Depending on the amount of available data and the type of tasks, DL models may not necessarily be the best performing one. As an illustration, the simple baseline models by Rajkomar et al. <span class="citation" data-cites="1DssZebFm">[<a href="#ref-1DssZebFm">11</a>]</span> achieved performance comparable with that of DL in a number of clinical prediction tasks using electronic health records, which may be a surprise to many.</p>
<p>It is worth noting that many conventional machine learning methods (e.g., support vector machines, random forests) require parameter tuning. Instead of assuming that DL is better than other machine learning methods, researchers should investigate whether the baseline models are rigorously fine-tuned. The performance comparison among DL models and many other ML approaches is informative only when the models are fairly compared.</p>
<h2 id="complexities">Tip 3: Understand the complexities of training deep neural networks</h2>
<h2 id="know-your-problem">Tip 4: Know your data and your question</h2>
<p>Having a well-defined scientific question and a clear analysis plan is crucial for carrying out a successful deep learning project. Just like it would be inadvisable to step foot in a laboratory and begin experiments without having a defined endpoint, a deep learning project should not be undertaken without preparation. Foremost, it is important to assess if a dataset exists that can answer the biological question of interest; obtaining said data and associated metadata and reviewing the study protocol should be pursued as early on in the project as possible. A publication or resource might purportedly offer data that seems to be a good fit to test your hypothesis, but the act of obtaining the data can reveal numerous problems such as the data is unstructured when it is supposed to be structured, crucial metadata such as sample stratification is missing, or the usable sample size is different than what is reported. Data collection should be documented or a data collection protocol should be created and specified in the project documentation. Information such as the resource used, the date downloaded, and the version of the dataset, if any, will help minimize operational confusion and will allow for transparency during the publication process.</p>
<p>Once the data is obtained, it is easy to begin analyzing data without a good understanding of the study design, namely why the data was collected and how. Metadata has been standardized in many fields and can help with this (for example, see <span class="citation" data-cites="YuxbleXb">[<a href="#ref-YuxbleXb">12</a>]</span>), but if at all possible, seek out a subject matter expert who has experience with this type of data. Receiving first-hand knowledge of the “gotchas” of a dataset will minimize the amount of guesswork and increase the success rate of a deep learning project. For example, if the main reason why the data was collected was to test the impact of an intervention, then it may be the case that a randomized controlled trial was performed. However, it is not always possible to perform a randomized trial for ethical or practical reasons. Therefore, an observational study design is often considered, with the data either prospectively or retrospectively collected. In order to ensure similar distributions of important characteristics across study groups in the absence of randomization, individuals may be matched based on age, gender, or weight. Study designs will often have different assumptions and caveats, and these cannot be ignored during a data analysis. Many datasets are now passively collected or do not have a specific design, but even in this case it is important to know how individuals or samples were treated. Samples originating from the same study site, oversampling of ethnic groups or zip codes, and sample processing differences are all sources of variation that need to be accounted for.</p>
<p>Systematic biases, which can be induced by confounding variables, for example, can lead to artifacts or so-called “batch effects.” As a consequence, models may learn to rely on correlations that are irrelevant in the scientific context of the study and may result in misguided predictions and misleading conclusions <span class="citation" data-cites="mPnIAH38">[<a href="#ref-mPnIAH38">13</a>]</span>. Other study design considerations that should not be overlooked include knowing whether a study involves biological or technical replicates or both. For example, are some samples collected from the same individuals at different time points? Are those time points before and after some treatment? If one assumes that all the samples are independent but that is in fact not the case, a variety of issues may arise, including having a lower effective sample size than expected.</p>
<p>In general, deep learning has an increased tendency for overfitting, compared to classical methods, due to the large number of parameters being estimated, making issues of adequate sample size even more important (see <a href="#overfitting">Tip 7</a>). For a large dataset, overfitting may not be a concern, but the modeling power of deep learning may lead to more spurious correlations and thus incorrect interpretation of results (see <a href="#interpretation">Tip 9</a>). Finally, it is important to note that with the exception of very specific cases of unsupervised data analysis, it is generally the case that a molecular or imaging dataset does not have much value without appropriate clinical or demographic data; this must always be balanced with the need to protect patient privacy (see <a href="#privacy">Tip 10</a>). Looking at these data can also clarify the study design (for example, by seeing if all the individuals are adolescents or women) or at least help the analyst employing deep learning to know what questions to ask.</p>
<h2 id="architecture">Tip 5: Choose an appropriate neural network architecture and data representation</h2>
<h2 id="hyperparameters">Tip 6: Expect to tune hyperparameters extensively and systematically</h2>
<p>Deep neural networks have the ability to approximate arbitrary continuous functions, as long as the neural network contains enough hidden nodes <span class="citation" data-cites="1BnILgle7">[<a href="#ref-1BnILgle7">14</a>]</span>. However, this flexibility makes the training process somewhat challenging. Users should expect to systematically evaluate the impact of numerous hyperparameters when they aim to apply deep neural networks to new data or challenges.</p>
<p>Neural network architectures also have their own odd nuances that affect hyperparameter portability. For example, in variational autoencoders (VAEs) there are two elements that are being optimized, reconstruction and distribution loss <span class="citation" data-cites="NLVTJ9Lj">[<a href="#ref-NLVTJ9Lj">15</a>]</span>. In common implementations, the relative weights of each are a function of the number of input features (more increase the importance of reconstruction loss) and the number of features in the latent space (more increase the importance of the distribution loss). Users who apply a VAE architecture to a new dataset with more input features, even without changing any hyperparameters, alter the relative weights of the components of the loss function.</p>
<p>This flexibility also makes it difficult to evaluate the extent to which neural network methods are well-suited to solving a task. Hu and Greene <span class="citation" data-cites="5CsWRjfp">[<a href="#ref-5CsWRjfp">16</a>]</span> discuss a Continental Breakfast Included (CBI) effect by which unequal hyperparameter tuning skews the evaluation of methods, especially those with performance that varies substantially with modest changes to hyperparameters. The implication of CBI on methods developers is discussed more in <a href="#baselines">Tip 2</a> (<code>TODO: cgreene tie these together</code>). The implication of CBI on users of deep neural networks is that attaining performance numbers that match those reported in publications is likely to require an input of human and compute time for hyperparameter optimization.</p>
<h2 id="overfitting">Tip 7: Address deep neural networks’ increased tendency to overfit the dataset</h2>
<p>Overfitting is one of the most significant dangers faced by a deep learning practitioner. Put simply, overfitting occurs when a model fits patterns in the training data too closely, includes noise or non-scientifically relevant perturbations, or in the most extreme case, simply memorizes patterns in the training set. This subtle distinction is made clearer by seeing what happens when a model is tested on data to which it was not exposed during training: just as a student who memorizes exam materials struggles to correctly answer questions for which they have not studied, a machine learning model that has overfit to its training data will perform poorly on unseen test data. Deep learning models are particularly susceptible to overfitting due to their relatively large number of parameters and associated representational capacity. To continue the student analogy, a smarter student has greater potential for memorization than average one and thus may be more inclined to memorize.</p>
<figure>
<img src="images/overfitting.png" alt="Figure 1: A visual example of overfitting. While a high-degree polynomial gets high accuracy on its training data, it performs poorly on data that is has not seen before, whereas a simple linear regression works well. The greater representational capacity of the polynomial is analogous to using a larger or deeper neural network." id="fig:overfitting-fig" /><figcaption><span>Figure 1:</span> A visual example of overfitting. While a high-degree polynomial gets high accuracy on its training data, it performs poorly on data that is has not seen before, whereas a simple linear regression works well. The greater representational capacity of the polynomial is analogous to using a larger or deeper neural network.</figcaption>
</figure>
<p>The simplest way to combat overfitting is to detect it. This can be done by splitting the dataset into three parts: a training set, a tuning set (also commonly called a validation set in the machine learning literature), and a test set. By exposing the model solely to the training data during fitting, a researcher can use the model’s performance on the unseen test data to measure the amount of overfitting. While a slight drop in performance from the training set to the test set is normal, a significant drop is a clear sign of overfitting (see Figure <a href="#fig:overfitting-fig">1</a> for a visual demonstration of an overfit model that performs poorly on test data). Additionally, there are a variety of techniques to reduce overfitting during training including data augmentation and regularization techniques such as dropout <span class="citation" data-cites="R1RpVu06">[<a href="#ref-R1RpVu06">17</a>]</span> and weight decay <span class="citation" data-cites="eR3C2hhK">[<a href="#ref-eR3C2hhK">18</a>]</span>. Another way, as described by Chuang and Keiser, is to identify the baseline level of memorization of the network by training on the data with the labels randomly shuffled and to see if the model performs better on the actual data <span class="citation" data-cites="yqAEYaMg">[<a href="#ref-yqAEYaMg">19</a>]</span>. If the model performs no better on real data than randomly scrambled data, then the performance of the model can be attributed to overfitting.</p>
<p>Additionally, one must be sure that their data are not skewed or biased, such as by having confounding and scientifically irrelevant variables that the model can pick up on <span class="citation" data-cites="FEPLn1Uo">[<a href="#ref-FEPLn1Uo">20</a>]</span>. In this case, simply holding out test data is insufficient. The best remedy for confounding variables is to <a href="#know-your-problem">know your data</a> and to test your model on truly independent data.</p>
<h2 id="blackbox">Tip 8: Do not necessarily consider a DL model as a black box</h2>
<h2 id="interpretation">Tip 9: Don’t over-interpret predictions</h2>
<p>Deep learning models can make predictions with high accuracy, but we need to take care to correctly interpret these predictions. We know that the basic tenets of machine learning also apply to deep learning (<a href="#concepts">Tip 1</a>), but because deep models can be difficult to interpret intuitively, there is a temptation to anthropomorphize deep models. We must resist this temptation.</p>
<p>A common saying in statistics classes is “correlation doesn’t imply causality”. While we know that accurately predicting an outcome doesn’t imply learning the causal mechanism, it can be easy to forget this lesson when the predictions are extremely accurate. A poignant example of this lesson is <span class="citation" data-cites="980FAm5x gSmt16Rh">[<a href="#ref-980FAm5x">21</a>,<a href="#ref-gSmt16Rh">22</a>]</span>. In this study, the authors evaluated the capacities of several models to predict the probability of death for patients admitted to an intensive care unit with pneumonia. Unsurprisingly, the neural network model achieved the best predictive accuracy. However, after fitting a rule-based model, the authors discovered that the hospital data implied the rule “HasAsthma(x) =&gt; LowerRisk(x)”. This rule contradicts medical understanding - having asthma doesn’t make pneumonia better! This rule was supported by the data (pneumonia patients with a history of pneumonia tended to receive more aggressive care), so the neural network also learned to make predictions according to this rule. Guiding treatment decisions according to the predictions of the neural network would have been disastrous, even though the neural network had high predictive accuracy.</p>
<p>To trust the reasoning and scientific conclusions of deep learning models, combine knowledge of the data (<a href="#know-your-problem">Tip 4</a>) with inspection of the model (<a href="#blackbox">Tip 8</a>).</p>
<h2 id="privacy">Tip 10: Don’t share models trained on sensitive data</h2>
<p>One of the greatest opportunities for deep learning in biology is the ability for deep learning techniques to incorporate representation learning to extract information that can not readily be captured by traditional methods <span class="citation" data-cites="UeE0s74F">[<a href="#ref-UeE0s74F">23</a>]</span>. The abundance of features for each training example means that the representation learning of the deep learning models can capture information-rich abstractions of data during the training process. Therefore with both deep learning and traditional machine learning models (<em>e.g.</em> <em>k</em>-nearest neighbors models, which learn by memorizing the full training data), it is imperative not to share models trained on sensitive data. Applying deep learning to images of cats from the internet does not pose significant ethical, legal, or privacy problems; this is not the case when dealing with classified, confidential, trade secret, or other types of biological data that cannot be shared. For example, adversarial training techniques such as model inversion attacks can be used to exploit model predictions to recover recognizable images of people’s faces used for training <span class="citation" data-cites="zCqhgXvY">[<a href="#ref-zCqhgXvY">24</a>]</span>. These risks are even more significant in deep learning compared to traditional machine learning techniques due to the greater representational capacity of the models. This is achieved by the large number of model weights, even in a relatively small project, that allow deep learning to model high-dimensional non-linear relationships among data. It is this enhanced modeling capacity that allows the model to learn more robust and nuanced features of specific data, leading to the danger of revealing the underlying sensitive data. When training deep learning models on sensitive data, be sure not to share the model weights directly, and use privacy preserving techniques <span class="citation" data-cites="1HuQe3Z8X">[<a href="#ref-1HuQe3Z8X">25</a>]</span> such as differential privacy <span class="citation" data-cites="LiCxcgZp eJgWbXRz">[<a href="#ref-LiCxcgZp">26</a>,<a href="#ref-eJgWbXRz">27</a>]</span> and homomorphic encryption <span class="citation" data-cites="me326jb9 3326vtLW">[<a href="#ref-me326jb9">28</a>,<a href="#ref-3326vtLW">29</a>]</span> to protect sensitive data.</p>
<h2 id="conclusion">Conclusion</h2>
<h2 id="references" class="page_break_before">References</h2>
<!-- Explicitly insert bibliography here -->
<div id="refs">
<div id="ref-PZMP42Ak">
<p>1. <strong>Opportunities and obstacles for deep learning in biology and medicine</strong><br />
Travers Ching, Daniel S. Himmelstein, Brett K. Beaulieu-Jones, Alexandr A. Kalinin, Brian T. Do, Gregory P. Way, Enrico Ferrero, Paul-Michael Agapow, Michael Zietz, Michael M. Hoffman, … Casey S. Greene<br />
<em>Journal of The Royal Society Interface</em> (2018-04) <a href="https://doi.org/gddkhn">https://doi.org/gddkhn</a><br />
DOI: <a href="https://doi.org/10.1098/rsif.2017.0387">10.1098/rsif.2017.0387</a> · PMID: <a href="http://www.ncbi.nlm.nih.gov/pubmed/29618526">29618526</a> · PMCID: <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5938574">PMC5938574</a></p>
</div>
<div id="ref-lwg6sPLT">
<p>2. <strong>VAMPnets for deep learning of molecular kinetics</strong><br />
Andreas Mardt, Luca Pasquali, Hao Wu, Frank Noé<br />
<em>Nature Communications</em> (2018-01-02) <a href="https://doi.org/gcvf62">https://doi.org/gcvf62</a><br />
DOI: <a href="https://doi.org/10.1038/s41467-017-02388-1">10.1038/s41467-017-02388-1</a> · PMID: <a href="http://www.ncbi.nlm.nih.gov/pubmed/29295994">29295994</a> · PMCID: <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5750224">PMC5750224</a></p>
</div>
<div id="ref-WGfstNkj">
<p>3. <strong>Deep learning to predict the lab-of-origin of engineered DNA</strong><br />
Alec A. K. Nielsen, Christopher A. Voigt<br />
<em>Nature Communications</em> (2018-08-07) <a href="https://doi.org/gd27sw">https://doi.org/gd27sw</a><br />
DOI: <a href="https://doi.org/10.1038/s41467-018-05378-z">10.1038/s41467-018-05378-z</a> · PMID: <a href="http://www.ncbi.nlm.nih.gov/pubmed/30087331">30087331</a> · PMCID: <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6081423">PMC6081423</a></p>
</div>
<div id="ref-p4Nl5If0">
<p>4. <strong>Ten quick tips for machine learning in computational biology</strong><br />
Davide Chicco<br />
<em>BioData Mining</em> (2017-12) <a href="https://doi.org/gdb9wr">https://doi.org/gdb9wr</a><br />
DOI: <a href="https://doi.org/10.1186/s13040-017-0155-3">10.1186/s13040-017-0155-3</a> · PMID: <a href="http://www.ncbi.nlm.nih.gov/pubmed/29234465">29234465</a> · PMCID: <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5721660">PMC5721660</a></p>
</div>
<div id="ref-ysdRl4lj">
<p>5. <strong>Ten Quick Tips for Deep Learning in Biology. Contribute to Benjamin-Lee/deep-rules development by creating an account on GitHub</strong><br />
Benjamin Lee<br />
(2019-02-11) <a href="https://github.com/Benjamin-Lee/deep-rules">https://github.com/Benjamin-Lee/deep-rules</a></p>
</div>
<div id="ref-1GGGHdsew">
<p>6. <strong>Open collaborative writing with Manubot</strong><br />
Daniel S. Himmelstein, David R. Slochower, Venkat S. Malladi, Casey S. Greene, Anthony Gitter<br />
(2019-02-09) <a href="https://greenelab.github.io/meta-review/">https://greenelab.github.io/meta-review/</a></p>
</div>
<div id="ref-u86hHJ9b">
<p>7. <strong>The precision-recall plot is more informative than the ROC plot when evaluating binary classifiers on imbalanced datasets.</strong><br />
Takaya Saito, Marc Rehmsmeier<br />
<em>PloS one</em> (2015-03-04) <a href="https://www.ncbi.nlm.nih.gov/pubmed/25738806">https://www.ncbi.nlm.nih.gov/pubmed/25738806</a><br />
DOI: <a href="https://doi.org/10.1371/journal.pone.0118432">10.1371/journal.pone.0118432</a> · PMID: <a href="http://www.ncbi.nlm.nih.gov/pubmed/25738806">25738806</a> · PMCID: <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4349800">PMC4349800</a></p>
</div>
<div id="ref-rKXyJKNt">
<p>8. <strong>Comparison of Deep Learning With Multiple Machine Learning Methods and Metrics Using Diverse Drug Discovery Data Sets</strong><br />
Alexandru Korotcov, Valery Tkachenko, Daniel P. Russo, Sean Ekins<br />
<em>Molecular Pharmaceutics</em> (2017-11-13) <a href="https://doi.org/gcj4p2">https://doi.org/gcj4p2</a><br />
DOI: <a href="https://doi.org/10.1021/acs.molpharmaceut.7b00578">10.1021/acs.molpharmaceut.7b00578</a> · PMID: <a href="http://www.ncbi.nlm.nih.gov/pubmed/29096442">29096442</a> · PMCID: <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5741413">PMC5741413</a></p>
</div>
<div id="ref-uBcf6TJ2">
<p>9. <strong>Deep k-Nearest Neighbors: Towards Confident, Interpretable and Robust Deep Learning</strong><br />
Nicolas Papernot, Patrick McDaniel<br />
<em>arXiv</em> (2018-03-13) <a href="https://arxiv.org/abs/1803.04765v1">https://arxiv.org/abs/1803.04765v1</a></p>
</div>
<div id="ref-2bsGpiQt">
<p>10. <strong>To Trust Or Not To Trust A Classifier</strong><br />
Heinrich Jiang, Been Kim, Melody Y. Guan, Maya Gupta<br />
<em>arXiv</em> (2018-05-30) <a href="https://arxiv.org/abs/1805.11783v2">https://arxiv.org/abs/1805.11783v2</a></p>
</div>
<div id="ref-1DssZebFm">
<p>11. <strong>Scalable and accurate deep learning with electronic health records</strong><br />
Alvin Rajkomar, Eyal Oren, Kai Chen, Andrew M. Dai, Nissan Hajaj, Michaela Hardt, Peter J. Liu, Xiaobing Liu, Jake Marcus, Mimi Sun, … Jeffrey Dean<br />
<em>npj Digital Medicine</em> (2018-05-08) <a href="https://doi.org/gdqcc8">https://doi.org/gdqcc8</a><br />
DOI: <a href="https://doi.org/10.1038/s41746-018-0029-1">10.1038/s41746-018-0029-1</a></p>
</div>
<div id="ref-YuxbleXb">
<p>12. <strong>Minimum information about a microarray experiment (MIAME)—toward standards for microarray data</strong><br />
Alvis Brazma, Pascal Hingamp, John Quackenbush, Gavin Sherlock, Paul Spellman, Chris Stoeckert, John Aach, Wilhelm Ansorge, Catherine A. Ball, Helen C. Causton, … Martin Vingron<br />
<em>Nature Genetics</em> (2001-12) <a href="https://doi.org/ck257n">https://doi.org/ck257n</a><br />
DOI: <a href="https://doi.org/10.1038/ng1201-365">10.1038/ng1201-365</a> · PMID: <a href="http://www.ncbi.nlm.nih.gov/pubmed/11726920">11726920</a></p>
</div>
<div id="ref-mPnIAH38">
<p>13. <strong>Tackling the widespread and critical impact of batch effects in high-throughput data</strong><br />
Jeffrey T. Leek, Robert B. Scharpf, Héctor Corrada Bravo, David Simcha, Benjamin Langmead, W. Evan Johnson, Donald Geman, Keith Baggerly, Rafael A. Irizarry<br />
<em>Nature Reviews Genetics</em> (2010-09-14) <a href="https://doi.org/cfr324">https://doi.org/cfr324</a><br />
DOI: <a href="https://doi.org/10.1038/nrg2825">10.1038/nrg2825</a> · PMID: <a href="http://www.ncbi.nlm.nih.gov/pubmed/20838408">20838408</a> · PMCID: <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3880143">PMC3880143</a></p>
</div>
<div id="ref-1BnILgle7">
<p>14. <strong>Approximation capabilities of multilayer feedforward networks</strong><br />
Kurt Hornik<br />
<em>Neural Networks</em> (1991) <a href="https://doi.org/dzwxkd">https://doi.org/dzwxkd</a><br />
DOI: <a href="https://doi.org/10.1016/0893-6080(91)90009-t">10.1016/0893-6080(91)90009-t</a></p>
</div>
<div id="ref-NLVTJ9Lj">
<p>15. <strong>Auto-Encoding Variational Bayes</strong><br />
Diederik P Kingma, Max Welling<br />
<em>arXiv</em> (2013-12-20) <a href="https://arxiv.org/abs/1312.6114v10">https://arxiv.org/abs/1312.6114v10</a></p>
</div>
<div id="ref-5CsWRjfp">
<p>16. <strong>Parameter tuning is a key part of dimensionality reduction via deep variational autoencoders for single cell RNA transcriptomics</strong><br />
Qiwen Hu, Casey S Greene<br />
<em>Cold Spring Harbor Laboratory</em> (2018-08-05) <a href="https://doi.org/gdxxjf">https://doi.org/gdxxjf</a><br />
DOI: <a href="https://doi.org/10.1101/385534">10.1101/385534</a></p>
</div>
<div id="ref-R1RpVu06">
<p>17. <strong>Dropout: A Simple Way to Prevent Neural Networks from Overfitting</strong><br />
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, Ruslan Salakhutdinov<br />
<em>Journal of Machine Learning Research</em> (2014) <a href="http://jmlr.org/papers/v15/srivastava14a.html">http://jmlr.org/papers/v15/srivastava14a.html</a></p>
</div>
<div id="ref-eR3C2hhK">
<p>18. <strong>A Simple Weight Decay Can Improve Generalization</strong><br />
Anders Krogh, John A. Hertz<br />
<em>Proceedings of the 4th International Conference on Neural Information Processing Systems</em> (1991) <a href="http://dl.acm.org/citation.cfm?id=2986916.2987033">http://dl.acm.org/citation.cfm?id=2986916.2987033</a><br />
ISBN: <a href="https://worldcat.org/isbn/9781558602229">9781558602229</a></p>
</div>
<div id="ref-yqAEYaMg">
<p>19. <strong>Adversarial Controls for Scientific Machine Learning</strong><br />
Kangway V. Chuang, Michael J. Keiser<br />
<em>ACS Chemical Biology</em> (2018-10-19) <a href="https://doi.org/gfk9mh">https://doi.org/gfk9mh</a><br />
DOI: <a href="https://doi.org/10.1021/acschembio.8b00881">10.1021/acschembio.8b00881</a> · PMID: <a href="http://www.ncbi.nlm.nih.gov/pubmed/30336670">30336670</a></p>
</div>
<div id="ref-FEPLn1Uo">
<p>20. <strong>Confounding variables can degrade generalization performance of radiological deep learning models</strong><br />
John R. Zech, Marcus A. Badgeley, Manway Liu, Anthony B. Costa, Joseph J. Titano, Eric K. Oermann<br />
<em>arXiv</em> (2018-07-02) <a href="https://arxiv.org/abs/1807.00431v2">https://arxiv.org/abs/1807.00431v2</a></p>
</div>
<div id="ref-980FAm5x">
<p>21. <strong>An evaluation of machine-learning methods for predicting pneumonia mortality</strong><br />
Gregory F. Cooper, Constantin F. Aliferis, Richard Ambrosino, John Aronis, Bruce G. Buchanan, Richard Caruana, Michael J. Fine, Clark Glymour, Geoffrey Gordon, Barbara H. Hanusa, … Peter Spirtes<br />
<em>Artificial Intelligence in Medicine</em> (1997-02) <a href="https://doi.org/b6vnmd">https://doi.org/b6vnmd</a><br />
DOI: <a href="https://doi.org/10.1016/s0933-3657(96)00367-3">10.1016/s0933-3657(96)00367-3</a></p>
</div>
<div id="ref-gSmt16Rh">
<p>22. <strong>Intelligible Models for HealthCare</strong><br />
Rich Caruana, Yin Lou, Johannes Gehrke, Paul Koch, Marc Sturm, Noemie Elhadad<br />
<em>Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD ’15</em> (2015) <a href="https://doi.org/gftgxk">https://doi.org/gftgxk</a><br />
DOI: <a href="https://doi.org/10.1145/2783258.2788613">10.1145/2783258.2788613</a></p>
</div>
<div id="ref-UeE0s74F">
<p>23. <strong>Convolutional Networks on Graphs for Learning Molecular Fingerprints</strong><br />
David Duvenaud, Dougal Maclaurin, Jorge Aguilera-Iparraguirre, Rafael Gómez-Bombarelli, Timothy Hirzel, Alán Aspuru-Guzik, Ryan P. Adams<br />
<em>arXiv</em> (2015-09-30) <a href="https://arxiv.org/abs/1509.09292v2">https://arxiv.org/abs/1509.09292v2</a></p>
</div>
<div id="ref-zCqhgXvY">
<p>24. <strong>Model Inversion Attacks that Exploit Confidence Information and Basic Countermeasures</strong><br />
Matt Fredrikson, Somesh Jha, Thomas Ristenpart<br />
<em>Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security - CCS ’15</em> (2015) <a href="https://doi.org/cwdm">https://doi.org/cwdm</a><br />
DOI: <a href="https://doi.org/10.1145/2810103.2813677">10.1145/2810103.2813677</a></p>
</div>
<div id="ref-1HuQe3Z8X">
<p>25. <strong>A generic framework for privacy preserving deep learning</strong><br />
Theo Ryffel, Andrew Trask, Morten Dahl, Bobby Wagner, Jason Mancuso, Daniel Rueckert, Jonathan Passerat-Palmbach<br />
<em>arXiv</em> (2018-11-09) <a href="https://arxiv.org/abs/1811.04017v2">https://arxiv.org/abs/1811.04017v2</a></p>
</div>
<div id="ref-LiCxcgZp">
<p>26. <strong>Deep Learning with Differential Privacy</strong><br />
Martin Abadi, Andy Chu, Ian Goodfellow, H. Brendan McMahan, Ilya Mironov, Kunal Talwar, Li Zhang<br />
<em>Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security - CCS’16</em> (2016) <a href="https://doi.org/gcrnp3">https://doi.org/gcrnp3</a><br />
DOI: <a href="https://doi.org/10.1145/2976749.2978318">10.1145/2976749.2978318</a></p>
</div>
<div id="ref-eJgWbXRz">
<p>27. <strong>Privacy-Preserving Distributed Deep Learning for Clinical Data</strong><br />
Brett K. Beaulieu-Jones, William Yuan, Samuel G. Finlayson, Zhiwei Steven Wu<br />
<em>arXiv</em> (2018-12-04) <a href="https://arxiv.org/abs/1812.01484v1">https://arxiv.org/abs/1812.01484v1</a></p>
</div>
<div id="ref-me326jb9">
<p>28. <strong>SIG-DB: Leveraging homomorphic encryption to securely interrogate privately held genomic databases</strong><br />
Alexander J. Titus, Audrey Flower, Patrick Hagerty, Paul Gamble, Charlie Lewis, Todd Stavish, Kevin P. O’Connell, Greg Shipley, Stephanie M. Rogers<br />
<em>PLOS Computational Biology</em> (2018-09-04) <a href="https://doi.org/gd6xd5">https://doi.org/gd6xd5</a><br />
DOI: <a href="https://doi.org/10.1371/journal.pcbi.1006454">10.1371/journal.pcbi.1006454</a> · PMID: <a href="http://www.ncbi.nlm.nih.gov/pubmed/30180163">30180163</a> · PMCID: <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6138421">PMC6138421</a></p>
</div>
<div id="ref-3326vtLW">
<p>29. <strong>The AlexNet Moment for Homomorphic Encryption: HCNN, the First Homomorphic CNN on Encrypted Data with GPUs</strong><br />
Ahmad Al Badawi, Jin Chao, Jie Lin, Chan Fook Mun, Sim Jun Jie, Benjamin Hong Meng Tan, Xiao Nan, Khin Mi Mi Aung, Vijay Ramaseshan Chandrasekhar<br />
<em>arXiv</em> (2018-11-02) <a href="https://arxiv.org/abs/1811.00778v1">https://arxiv.org/abs/1811.00778v1</a></p>
</div>
</div>
<script>
// AnchorJS minified version below.
// Source https://github.com/bryanbraun/anchorjs/blob/064abdd0987f305933ec4982af6d0c1cf2fd0814/anchor.js

/**
 * AnchorJS - v4.0.0 - 2017-06-02
 * https://github.com/bryanbraun/anchorjs
 * Copyright (c) 2017 Bryan Braun; Licensed MIT
 */
!function(A,e){"use strict";"function"==typeof define&&define.amd?define([],e):"object"==typeof module&&module.exports?module.exports=e():(A.AnchorJS=e(),A.anchors=new A.AnchorJS)}(this,function(){"use strict";function A(A){function e(A){A.icon=A.hasOwnProperty("icon")?A.icon:"",A.visible=A.hasOwnProperty("visible")?A.visible:"hover",A.placement=A.hasOwnProperty("placement")?A.placement:"right",A.class=A.hasOwnProperty("class")?A.class:"",A.truncate=A.hasOwnProperty("truncate")?Math.floor(A.truncate):64}function t(A){var e;if("string"==typeof A||A instanceof String)e=[].slice.call(document.querySelectorAll(A));else{if(!(Array.isArray(A)||A instanceof NodeList))throw new Error("The selector provided to AnchorJS was invalid.");e=[].slice.call(A)}return e}function n(){if(null===document.head.querySelector("style.anchorjs")){var A,e=document.createElement("style");e.className="anchorjs",e.appendChild(document.createTextNode("")),void 0===(A=document.head.querySelector('[rel="stylesheet"], style'))?document.head.appendChild(e):document.head.insertBefore(e,A),e.sheet.insertRule(" .anchorjs-link {   opacity: 0;   text-decoration: none;   -webkit-font-smoothing: antialiased;   -moz-osx-font-smoothing: grayscale; }",e.sheet.cssRules.length),e.sheet.insertRule(" *:hover > .anchorjs-link, .anchorjs-link:focus  {   opacity: 1; }",e.sheet.cssRules.length),e.sheet.insertRule(" [data-anchorjs-icon]::after {   content: attr(data-anchorjs-icon); }",e.sheet.cssRules.length),e.sheet.insertRule(' @font-face {   font-family: "anchorjs-icons";   src: url(data:n/a;base64,AAEAAAALAIAAAwAwT1MvMg8yG2cAAAE4AAAAYGNtYXDp3gC3AAABpAAAAExnYXNwAAAAEAAAA9wAAAAIZ2x5ZlQCcfwAAAH4AAABCGhlYWQHFvHyAAAAvAAAADZoaGVhBnACFwAAAPQAAAAkaG10eASAADEAAAGYAAAADGxvY2EACACEAAAB8AAAAAhtYXhwAAYAVwAAARgAAAAgbmFtZQGOH9cAAAMAAAAAunBvc3QAAwAAAAADvAAAACAAAQAAAAEAAHzE2p9fDzz1AAkEAAAAAADRecUWAAAAANQA6R8AAAAAAoACwAAAAAgAAgAAAAAAAAABAAADwP/AAAACgAAA/9MCrQABAAAAAAAAAAAAAAAAAAAAAwABAAAAAwBVAAIAAAAAAAIAAAAAAAAAAAAAAAAAAAAAAAMCQAGQAAUAAAKZAswAAACPApkCzAAAAesAMwEJAAAAAAAAAAAAAAAAAAAAARAAAAAAAAAAAAAAAAAAAAAAQAAg//0DwP/AAEADwABAAAAAAQAAAAAAAAAAAAAAIAAAAAAAAAIAAAACgAAxAAAAAwAAAAMAAAAcAAEAAwAAABwAAwABAAAAHAAEADAAAAAIAAgAAgAAACDpy//9//8AAAAg6cv//f///+EWNwADAAEAAAAAAAAAAAAAAAAACACEAAEAAAAAAAAAAAAAAAAxAAACAAQARAKAAsAAKwBUAAABIiYnJjQ3NzY2MzIWFxYUBwcGIicmNDc3NjQnJiYjIgYHBwYUFxYUBwYGIwciJicmNDc3NjIXFhQHBwYUFxYWMzI2Nzc2NCcmNDc2MhcWFAcHBgYjARQGDAUtLXoWOR8fORYtLTgKGwoKCjgaGg0gEhIgDXoaGgkJBQwHdR85Fi0tOAobCgoKOBoaDSASEiANehoaCQkKGwotLXoWOR8BMwUFLYEuehYXFxYugC44CQkKGwo4GkoaDQ0NDXoaShoKGwoFBe8XFi6ALjgJCQobCjgaShoNDQ0NehpKGgobCgoKLYEuehYXAAAADACWAAEAAAAAAAEACAAAAAEAAAAAAAIAAwAIAAEAAAAAAAMACAAAAAEAAAAAAAQACAAAAAEAAAAAAAUAAQALAAEAAAAAAAYACAAAAAMAAQQJAAEAEAAMAAMAAQQJAAIABgAcAAMAAQQJAAMAEAAMAAMAAQQJAAQAEAAMAAMAAQQJAAUAAgAiAAMAAQQJAAYAEAAMYW5jaG9yanM0MDBAAGEAbgBjAGgAbwByAGoAcwA0ADAAMABAAAAAAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAAH//wAP) format("truetype"); }',e.sheet.cssRules.length)}}this.options=A||{},this.elements=[],e(this.options),this.isTouchDevice=function(){return!!("ontouchstart"in window||window.DocumentTouch&&document instanceof DocumentTouch)},this.add=function(A){var i,o,s,c,r,a,h,l,u,d,f,g,p=[];if(e(this.options),"touch"===(g=this.options.visible)&&(g=this.isTouchDevice()?"always":"hover"),A||(A="h2, h3, h4, h5, h6"),0===(i=t(A)).length)return this;for(n(),o=document.querySelectorAll("[id]"),s=[].map.call(o,function(A){return A.id}),r=0;r<i.length;r++)if(this.hasAnchorJSLink(i[r]))p.push(r);else{if(i[r].hasAttribute("id"))c=i[r].getAttribute("id");else if(i[r].hasAttribute("data-anchor-id"))c=i[r].getAttribute("data-anchor-id");else{u=l=this.urlify(i[r].textContent),h=0;do{void 0!==a&&(u=l+"-"+h),a=s.indexOf(u),h+=1}while(-1!==a);a=void 0,s.push(u),i[r].setAttribute("id",u),c=u}d=c.replace(/-/g," "),(f=document.createElement("a")).className="anchorjs-link "+this.options.class,f.href="#"+c,f.setAttribute("aria-label","Anchor link for: "+d),f.setAttribute("data-anchorjs-icon",this.options.icon),"always"===g&&(f.style.opacity="1"),""===this.options.icon&&(f.style.font="1em/1 anchorjs-icons","left"===this.options.placement&&(f.style.lineHeight="inherit")),"left"===this.options.placement?(f.style.position="absolute",f.style.marginLeft="-1em",f.style.paddingRight="0.5em",i[r].insertBefore(f,i[r].firstChild)):(f.style.paddingLeft="0.375em",i[r].appendChild(f))}for(r=0;r<p.length;r++)i.splice(p[r]-r,1);return this.elements=this.elements.concat(i),this},this.remove=function(A){for(var e,n,i=t(A),o=0;o<i.length;o++)(n=i[o].querySelector(".anchorjs-link"))&&(-1!==(e=this.elements.indexOf(i[o]))&&this.elements.splice(e,1),i[o].removeChild(n));return this},this.removeAll=function(){this.remove(this.elements)},this.urlify=function(A){var t=/[& +$,:;=?@"#{}|^~[`%!'<>\]\.\/\(\)\*\\]/g;return this.options.truncate||e(this.options),A.trim().replace(/\'/gi,"").replace(t,"-").replace(/-{2,}/g,"-").substring(0,this.options.truncate).replace(/^-+|-+$/gm,"").toLowerCase()},this.hasAnchorJSLink=function(A){var e=A.firstChild&&(" "+A.firstChild.className+" ").indexOf(" anchorjs-link ")>-1,t=A.lastChild&&(" "+A.lastChild.className+" ").indexOf(" anchorjs-link ")>-1;return e||t||!1}}return A});

// Enable links for selected headers
var anchors = new AnchorJS();
anchors.add("h2, h3, h4")
</script>
<!-- Enable Hypothesis annotation. https://web.hypothes.is/ -->
<script src="https://hypothes.is/embed.js" async></script>
</body>
</html>
