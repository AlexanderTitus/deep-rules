## Tip 1: Decide whether your problem is appropriate for deep learning {#appropriate}

Given the impressive accomplishments of DL in recent years and the meteoric rise in publications which rely upon it may appear that DL is capable of anything.
Indeed, it is, at least theoretically.
Neural networks are universal function approximators, meaning that they are in principle capable of learning any function [@doi:10.1007/BF02551274; @tag:hornik-approximation].
If DL is so powerful and popular, why would one ever not choose to use it?

The reason is simple: DL is not suited to every situation in reality.
Training DL models requires a significant amount of data, computing power, and expertise.
In some areas of biology where data collection is thoroughly automated, such as DNA sequencing, large amounts of quality data may be available.
For other areas which rely on manual data collection, there may not be enough data to effectively train models.
As a rule of thumb, DL should only be considered for datasets with at least ten thousand samples, though it is best suited to cases when datasets contain orders of magnitude more samples.

Depending on the amount and the nature of the available data, as well as the task to be performed, deep learning may not always be able to outperform conventional methods.
As an illustration, Rajkomar et al. [@doi:10.1038/s41746-018-0029-1] found that simpler baseline models achieved performance comparable with that of DL in a number of clinical prediction tasks using electronic health records, which may be a surprise to many.
Another example is provided by Koutsoukas et al., who benchmarked several traditional machine learning approaches against deep neural networks for modeling bioactivity data on moderately sized datasets [@doi:10.1186/s13321-017-0226-y].
The researchers found that while well tuned deep learning approaches generally tend to outperform conventional classifiers, simple methods such as Naive Bayes classification tend to outperform deep learning as the noise in the dataset increases.
Similarly, Chen et al. [@doi:s41746-019-0122-0] tested deep learning and a variety of traditional ML methods such as logistic regression and random forests on five different clinical datasets, finding that the non-DL methods matched or exceeded the accuracy of the DL model in all cases while requiring an order of magnitude less training time.
