---
author-meta:
- Benjamin D. Lee
date-meta: '2019-01-09'
keywords:
- quick tips
- machine learning
- deep learning
- artificial intelligence
lang: en-US
title: Ten Quick Tips for Deep Learning in Biology
...






<small><em>
This manuscript
([permalink](https://Benjamin-Lee.github.io/deep-rules/v/d06f69cdff98dda0451d0dee6b2992b7d360c049/))
was automatically generated
from [Benjamin-Lee/deep-rules@d06f69c](https://github.com/Benjamin-Lee/deep-rules/tree/d06f69cdff98dda0451d0dee6b2992b7d360c049)
on January 9, 2019.
</em></small>

## Authors



+ **Benjamin D. Lee**<br>
    ![ORCID icon](images/orcid.svg){height="13px" width="13px"}
    [0000-0002-7133-8397](https://orcid.org/0000-0002-7133-8397)
    · ![GitHub icon](images/github.svg){height="13px" width="13px"}
    [Benjamin-Lee](https://github.com/Benjamin-Lee)<br>
  <small>
     School of Engineering and Applied Sciences, Harvard University; Department of Genetics, Harvard Medical School; Lab41, In-Q-Tel
  </small>



## Introduction {#intro}

Deep learning (DL), a subfield of machine learning (ML) implementing artificial neural networks with many layers, is increasingly used for the analysis of biological data [@PZMP42Ak].
Despite its growing popularity, DL itself remains an active area of research. Its everchanging complexity and lack of current beginner resources focused on biological applications pose large barriers of entry to newcomers who wish to utilize state-of-the-art DL in their research.
Biological insight garnered from DL has been well-documented in the scientific literature, with applications ranging from predicting protein-drug binding kinetics [@lwg6sPLT] to identifying the lab-of-origin of synthetic DNA [@WGfstNkj]. However, few resources articulate DL best practices to the scientific community. Most instructional literature focuses on ML broadly, rather than DL specifically, further limiting accessibility and reproducibility [@p4Nl5If0].
To address this issue, we solicited input from a diverse community of researchers, who wrote this manuscript collaboratively using the GitHub version control platform [@ysdRl4lj] and Manubot [@1GGGHdsew].

In the course of our discussions, several themes became clear: the importance of understanding and applying ML fundamentals as a baseline for utilizing DL, the necessity for extensive model comparisons and careful evaluation, and the need for critical thought in interpreting results generated by means of DL, among others.
Ultmately, the tips we established range from high-level guidance to the implementation of best practices, and it is our hope that they will provide actionable, DL-specific advice for both new and experienced DL practitioners alike who would like to employ DL in biological research.
By increasing the accessibility of DL techniques to biology, we aim to improve the overall quality and reproducibility of DL in the literature, enabling these powerful methods to be properly utilized to generate new scientific insights.


## Tip 1: Concepts that apply to machine learning also apply to deep learning {#concepts}
Deep learning is a distinct subfield of machine learning, but it is still a subfield.
Deep learning has proven to be an extremely powerful paradigm capable of outperforming “traditional” machine learning approaches, but it is not immune to the many limitations inherent to machine learning.
Many best practices for machine learning apply to deep learning as well.
For instance, deep supervised learning models should be trained, tuned, and tested on non-overlapping datasets.
Those developing deep learning models should select data that are relevant to the problem at hand; non-salient data can hamper performance or lead to spurious conclusions.
Furthermore, investigators should begin by thoroughly inspecting their data.
When coupled with imprudence, data that is biased, skewed, or of low quality will produce models of dubious performance and limited generalizability.
Biases in testing data can also unduly influence measures of model performance.
For example, many conventional metrics for classification (e.g. area under the receiver operating characteristic curve or AUROC) have limited utility in cases of extreme class imbalance.
As such, model performance should be evaluated with a carefully-picked panel of relevant metrics that make minimal assumptions about the composition of the testing data [@rKXyJKNt].
Extreme cases warrant testing the robustness of the model and metrics on simulated data for which the ground truth is known.
Said simulations can be used to verify the correctness of the model’s implementation as well.
Like all computational methods, deep learning should be leveraged in a systematic manner that is reproducible and rigorously tested.


## Tip 2: Use traditional methods to establish performance baselines {#baselines}

Before diving into a fancy thousand-layer neural network, always implement at least a simple model to establish an adequate performance baseline. 
For example, researchers can build multinomial logistic regression or random forest models using the same software framework that is being used for DL and evaluate its classification performance. 
This approach will help researchers with assessing the complexity of the task at hand and debugging more complex DL architectures. 
Depending on the amount of available data and the type of tasks, DL models may not necessarily be the best performing one. 
As an illustration, the simple baseline models by Rajkomar A et al. [@1DssZebFm] had achieved performance comparable with that of DL in a number of clinical prediction tasks using electronic health records, which may be a surprise to many. 

It is worth noting that many conventional machine learning methods (e.g., support vector machines, random forests) require parameter tuning. 
Instead of assuming that DL is better than other machine learning methods, researchers should investigate whether the baseline models are rigorously fine-tuned. 
The performance comparison among DL models and many other ML approaches is informative only when the models are fairly compared.


## Tip 3: Understand the complexities of training deep neural networks {#complexities}


## Tip 4: Know your data and your question {#know-your-problem}

In the era of easily accessible datasets, one sometimes starts analyzing data without a good understanding of the study design, namely why the data were collected and how. 
Having appropriate meta-data, a comprehensive data dictionary, and even the actual data collection protocol is essential for any analysis, including one that involves deep learning. 
It's even better to also have access to a subject matter expert who has either collected or analyzed this type of data before! 
For example, if the main reason why the data were collected was to test the impact of an intervention, it may be the case that a randomized controlled trial was performed.
However, ethical or other study considerations may make this impossible or impractical, in which case the design may have been an observational one, either prospective or retrospective.
These designs may also incorporate some amount of matching - for example, cases and controls may be selected so that the age range or weight distribution is similar.
All of these different designs have different assumptions and caveats, which cannot be ignored during a data analysis.
Many datasets are now passively collected or do not have a specific design, but even in this case it is important to know how individuals or samples were treated (for example, if all samples are from the same study site, if certain ethnic groups or zip codes are oversampled, if there are differences in processing dates or techniques.)

Systematic biases can lead to artifacts or "batch effects," which mean that instead of finding correlates with an outcome or grouping of interest, the investigator may find correlates with variables that are not of interest and obtain misleading results [@mPnIAH38].
Other study design considerations that should not be overlooked include knowing whether a study involves biological or technical replicates or both.
For example, are some samples collected from the same individuals at different time points? Are those time points before and after some treatment?
If one assumes that all the samples are independent but that is in fact not the case, a variety of issues may arise, including having a lower effective sample size than expected.

In general, deep learning has an increased tendency for overfitting, compared to classical methods, due to the large number of parameters being estimated, making issues of adequate sample size even more important (see [Rule 7](#overfitting)).
For a large dataset, overfitting may not be a concern, but the modeling power of deep learning may lead to more spurious correlations and thus incorrect interpretation of results (see [Rule 9](#interpretation)).
Finally, it is important to note that with the exception of very specific cases of unsupervised data analysis, it is generally the case that a molecular or imaging dataset does not have much value without appropriate clinical or demographic data; this must always be balanced with the need to protect patient privacy (see [Rule 10](#privacy)). 
Looking at these data can also clarify the study design (for example, by seeing if all the individuals are adolescents or women) or at least help the analyst employing deep learning to know what questions to ask.


## Tip 5: Choose an appropriate neural network architecture and data representation {#architecture}


## Tip 6: Expect to tune hyperparameters extensively and systematically {#hyperparameters}

Deep neural networks have the ability to approximate arbitrary continuous functions, as long as the neural network contains enough hidden nodes [@1BnILgle7].
However, this flexibility makes the training process somewhat challenging.
Users should expect to systematically evaluate the impact of numerous hyperparameters when they aim to apply deep neural networks to new data or challenges.

Neural network architectures also have their own odd nuances that affect hyperparameter portability.
For example, in variational autoencoders (VAEs) there are two elements that are being optimized, reconstruction and distribution loss [@NLVTJ9Lj].
In common implementations, the relative weights of each are a function of the number of input features (more increase the importance of reconstruction loss) and the number of features in the latent space (more increase the importance of the distribution loss).
Users who apply a VAE architecture to a new dataset with more input features, even without changing any hyperparameters, alter the relative weights of the components of the loss function.

This flexibility also makes it difficult to evaluate the extent to which neural network methods are well-suited to solving a task.
Hu and Greene [@5CsWRjfp] discuss a Continental Breakfast Included (CBI) effect by which unequal hyperparameter tuning skews the evaluation of methods, especially those with performance that varies substantially with modest changes to hyperparameters.
The implication of CBI on methods developers is discussed more in Rule 2 (`TODO: cgreene tie these together`).
The implication of CBI on users of deep neural networks is that attaining performance numbers that match those reported in publications is likely to require an input of human and compute time for hyperparameter optimization.


## Tip 7: Address deep neural networks' increased tendency to overfit the dataset {#overfitting}


## Tip 8: Do not necessarily consider a DL model as a black box {#blackbox}


## Tip 9: Interpret predictions in the correct manner {#interpretation}


## Tip 10: Don't share models trained on sensitive data {#privacy}

One of the greatest opportunities for deep learning in biology is the ability for deep learning techniques to incorporate representation learning to extract information that can not readily be captured by traditional methods [@UeE0s74F].
The abundance of features for each training example means that the representation learning of the deep learning models can capture information-rich abstractions of data during the training process.
Therefore with both deep learning and traditional machine learning models (_e.g._ _k_-nearest neighbors models, which learn by memorizing the full training data), it is imperative not to share models trained on sensitive data.
Applying deep learning to images of cats from the internet does not pose significant ethical, legal, or privacy problems; this is not the case when dealing with classified, confidential, trade secret, or other types of biological data that cannot be shared.
For example, adversarial training techniques such as model inversion attacks can be used to exploit model predictions to recover recognizable images of people's faces used for training [@zCqhgXvY].
These risks are even more significant in deep learning compared to traditional machine learning techniques due to the greater representational capacity of the models.
This is achieved by the large number of model weights, even in a relatively small project, that allow deep learning to model high-dimensional non-linear relationships among data.
It is this enhanced modeling capacity that allows the model to learn more robust and nuanced features of specific data, leading to the danger of revealing the underlying sensitive data.
When training deep learning models on sensitive data, be sure not to share the model weights directly, and use privacy preserving techniques [@1HuQe3Z8X] such as differential privacy [@LiCxcgZp; @eJgWbXRz] and homomorphic encryption [@me326jb9; @3326vtLW] to protect sensitive data.


## Conclusion {#conclusion}


## References {.page_break_before}

<!-- Explicitly insert bibliography here -->
<div id="refs"></div>
